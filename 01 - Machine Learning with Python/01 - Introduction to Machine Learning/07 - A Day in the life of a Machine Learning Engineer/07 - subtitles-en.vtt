WEBVTT

1
00:00:05.120 --> 00:00:08.080
Welcome to A Day in the Life
of a Machine Learning Engineer.

2
00:00:08.880 --> 00:00:11.840
After watching this video, you will be able to:

3
00:00:11.840 --> 00:00:14.080
Describe the importance and requirements of

4
00:00:14.080 --> 00:00:17.200
each process in the lifecycle
of a machine learning model.

5
00:00:17.200 --> 00:00:21.453
And, name the processes that are
more time-consuming than others.

6
00:00:22.160 --> 00:00:25.280
Now, let’s go through the Lifecycle
of a Machine Learning Model

7
00:00:25.280 --> 00:00:27.468
in a project that I am currently working on.

8
00:00:27.920 --> 00:00:32.720
To help increase business revenue, I have
been tasked with creating and deploying a

9
00:00:32.720 --> 00:00:36.880
model that recommends similar products
to what the customer has already bought.

10
00:00:37.680 --> 00:00:42.348
I have worked together with the client
to come up with an end-user’s pain point:

11
00:00:42.800 --> 00:00:46.640
“As a beauty product customer, I would
like to receive recommendations for

12
00:00:46.640 --> 00:00:51.360
other products based on my purchase history so
that I will be able to address my skincare needs

13
00:00:51.360 --> 00:00:54.070
and improve the overall health of my skin.”

14
00:00:54.640 --> 00:01:00.080
Defining the problem or stating the
situation is very important, because I

15
00:01:00.080 --> 00:01:06.112
want to make sure the machine learning solution I
am providing is aligned with the client’s needs.

16
00:01:06.960 --> 00:01:13.120
Now, that I understand the client’s needs, the
next step is to begin data collection. I should

17
00:01:13.120 --> 00:01:18.400
determine what kind of data the company has
and identify the sources it will come from.

18
00:01:19.120 --> 00:01:23.120
This could be user data such as
demographics, purchase history,

19
00:01:23.120 --> 00:01:26.240
and anything related to completed transactions.

20
00:01:26.240 --> 00:01:32.480
I can also get the product data, that is,
the inventory of products and what they do,

21
00:01:32.480 --> 00:01:37.440
their ingredients, how popular they
are, their customer ratings, and so on.

22
00:01:38.240 --> 00:01:43.680
Further, I may look at other data that includes
information such as a user’s saved products,

23
00:01:43.680 --> 00:01:48.560
liked products, search history,
most visited products, and so on.

24
00:01:49.760 --> 00:01:55.760
Then, I will go ahead and do some major
transforming by wrangling, aggregating,

25
00:01:55.760 --> 00:02:00.080
joining, merging, and mapping
the data onto one central source.

26
00:02:00.800 --> 00:02:05.840
This reduces the need to deal with multiple
databases every time we need to pull data.

27
00:02:06.640 --> 00:02:11.600
The next step in the process is
data preparation. Most of the time,

28
00:02:11.600 --> 00:02:17.280
data from multiple sources will contain
errors, different formatting, and missing data.

29
00:02:18.240 --> 00:02:22.880
This process overlaps with the Data Collection
process as they can be done in tandem.

30
00:02:23.520 --> 00:02:28.480
The area of focus here is preparing
a somewhat final version of the data.

31
00:02:29.040 --> 00:02:31.120
I will need to make sure that

32
00:02:31.120 --> 00:02:34.080
the data is cleaned to filter out irrelevant data,

33
00:02:34.720 --> 00:02:38.240
extreme values are removed to
avoid influencing the data set,

34
00:02:38.800 --> 00:02:41.920
missing values are removed or randomly generated,

35
00:02:41.920 --> 00:02:45.840
depending on what the missing
data may mean, and that

36
00:02:45.840 --> 00:02:48.480
each data column is in the proper format.

37
00:02:49.040 --> 00:02:55.360
For example, dates should be in date formats
and strings should be properly identified.

38
00:02:56.240 --> 00:02:59.280
I may also need to create additional features.

39
00:02:59.280 --> 00:03:05.120
For example, I may need to calculate the average
duration between transactions for each user

40
00:03:05.120 --> 00:03:07.440
and find which products they buy the most.

41
00:03:08.000 --> 00:03:12.160
Or, I may need a feature that
identifies what kind of skin

42
00:03:12.160 --> 00:03:16.320
issues each product targets
and assign them to each user.

43
00:03:16.960 --> 00:03:20.160
I can create plots to visually identify patterns,

44
00:03:20.800 --> 00:03:26.960
validate the data based on information that the
beauty product subject matter expert has given me,

45
00:03:26.960 --> 00:03:34.000
and do some correlation analysis to identify
what variables or features are very important

46
00:03:34.000 --> 00:03:40.080
to the users’ buying habits and needs.
This is called Exploratory data analysis.

47
00:03:41.040 --> 00:03:46.000
I can also identify how I plan on splitting
the data for training and testing.

48
00:03:46.000 --> 00:03:52.960
For example, do I want to randomly split the data
or use the most recent transaction as a test set?

49
00:03:53.840 --> 00:03:59.040
In this example, I decided to put the most
recent transaction in the test set and make

50
00:03:59.040 --> 00:04:03.830
sure that there was at least one transaction
by that the same user in the training set.

51
00:04:05.223 --> 00:04:10.423
In the Model Development step, I will go
ahead and build a Machine Learning model.

52
00:04:10.880 --> 00:04:16.640
Realistically, I try to leverage as many
pre-existing frameworks and resources as possible,

53
00:04:16.640 --> 00:04:18.880
so I don’t create anything from scratch.

54
00:04:19.680 --> 00:04:24.240
For this task, I will use a technique
called content-based filtering.

55
00:04:24.880 --> 00:04:29.854
This technique finds the similarity
between products, based on product content.

56
00:04:30.240 --> 00:04:36.800
For example, if someone is using a cleanser with
lots of water, it is likely that the user has

57
00:04:36.800 --> 00:04:41.840
dry skin and will want a moisturizer
that is highly moisturizing as well.

58
00:04:42.560 --> 00:04:46.560
One of the steps I might take here
is to create a similarity score of

59
00:04:46.560 --> 00:04:50.720
the products a user has purchased
and rank them to other products.

60
00:04:51.280 --> 00:04:53.920
I might recommend the most similar product

61
00:04:53.920 --> 00:04:59.600
while bearing in mind that there may be other
factors that could come into play. For example,

62
00:04:59.600 --> 00:05:04.320
I might notice that the user has searched
for products without particular ingredients,

63
00:05:04.320 --> 00:05:06.480
so I want to make sure that we are not

64
00:05:06.480 --> 00:05:10.320
recommending a product that
they absolutely won’t use.

65
00:05:10.320 --> 00:05:15.520
I will also use a technique called Collaborative
Filtering that uses the user’s data.

66
00:05:16.320 --> 00:05:22.075
Here, I am creating similarities between
two users based on how they view a product.

67
00:05:22.560 --> 00:05:28.400
For example, I can create a similarity,
based on how two users rate their product.

68
00:05:29.120 --> 00:05:31.280
First, I group users into a bucket

69
00:05:31.280 --> 00:05:33.120
based on their characteristics.

70
00:05:33.120 --> 00:05:39.440
This could be age, region, and skin type,
products the users rated, and or purchased.

71
00:05:40.080 --> 00:05:43.600
Then, I can take the average
ratings for existing members

72
00:05:43.600 --> 00:05:48.320
and assume that the new user will
be somewhere around the average, and

73
00:05:48.320 --> 00:05:52.291
recommend a product based on
what others have rated highly.

74
00:05:52.720 --> 00:05:56.531
The final model will be a
combination of the two techniques.

75
00:05:57.440 --> 00:06:02.800
After I am done building the model, I will go
ahead and test that the model is performing well

76
00:06:02.800 --> 00:06:06.800
and that recommendations are
representing what the users want.

77
00:06:06.800 --> 00:06:09.520
This is called the Model Evaluation step;

78
00:06:10.640 --> 00:06:15.680
the initial stages of Model Evaluation
will involve me tuning the model and

79
00:06:15.680 --> 00:06:20.000
doing some testing on the data set
I had kept earlier for testing.

80
00:06:20.000 --> 00:06:22.160
Once I am satisfied with the results,

81
00:06:22.160 --> 00:06:24.320
I will further evaluate the model

82
00:06:24.320 --> 00:06:29.280
by experimenting with the recommendations on a
group of users and asking for their feedback.

83
00:06:30.080 --> 00:06:34.480
The feedback will include asking the group
of users to rate the recommendations,

84
00:06:35.040 --> 00:06:38.640
and collecting data on the
number of people who clicked

85
00:06:38.640 --> 00:06:43.360
and bought the recommended products,
along with any other necessary metrics.

86
00:06:44.480 --> 00:06:50.249
Now that I am done with building and testing,
the model is ready to go to production.

87
00:06:50.560 --> 00:06:54.560
For this project, it will be a part
of the beauty product app and website.

88
00:06:55.440 --> 00:06:59.600
While this is the last step, I still
need to track the deployed model’s

89
00:06:59.600 --> 00:07:04.000
performance to make sure it continues to
do the job that the business requires.

90
00:07:04.560 --> 00:07:09.440
Future iterations may include retraining
the model based on new information

91
00:07:09.440 --> 00:07:11.760
in order to expand its capabilities.

92
00:07:13.200 --> 00:07:15.840
In this video, you learned that:

93
00:07:15.840 --> 00:07:19.120
Each of the steps of the
Machine Learning Model Lifecycle

94
00:07:19.120 --> 00:07:21.760
is important to the success of the solution.

95
00:07:22.640 --> 00:07:27.120
After deployment, continuous
monitoring and improvement is required

96
00:07:27.120 --> 00:07:30.240
to ensure that the quality of
the solution is maintained.

97
00:07:31.120 --> 00:07:35.498
Thank you for watching, A Day in the
Life of a Machine Learning Engineer.