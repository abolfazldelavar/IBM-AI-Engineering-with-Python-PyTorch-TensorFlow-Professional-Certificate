Welcome to training a logistic regression model. After watching this video, you will be able to describe how to train a logistic regression model. You will also be able to explain the features of the gradient descent and stochastic gradient descent method. In logistical regression training, you look for the best parameters that map the input features to the target outcomes. The objective is to predict classes with minimal error. The training process seeks to find a set of parameters, also known as theta, that minimizes the cost function. The process of training a logistical regression model comprises several steps. First, you have to choose a starting set of parameters called theta. This can be a random choice. You then predict the probability that the class is 1 for each observation of your data. The next step is to measure the error between the predicted classes and the actual classes. This error is called a cost function. You then determine a new theta that reduces the prediction error. Finally, you need to repeat the process until you reach a small enough value for the log loss or a specified maximum number of iterations. Next, let's understand optimal logistic regression. The process of creating a decision boundary by combining a linear model y-hat in terms of parameters theta with a sigmoid function yields a binary classification model or what might be called a preliminary logistic regression. The model is called preliminary because it's not necessarily the best logistic regression model. The best logistic regression model can only be achieved after the first pass. The model parameters, theta, need to be found. An optimization step finds the best parameters. To achieve optimization, you need a metric that determines the model's goodness of fit for a given set of parameters. The metric for optimizing logistic regression is a cost function called log loss, which needs to be minimized. Log loss is a cost function that measures how well the predicted probabilities, p-hat i, match the actual class's yi. Logistic regression seeks to minimize this cost function. Here, i refers to the ith observation of the data, which is n rows. Log loss is defined as minus the average over i of two terms. The actual class times the logarithm of the predicted probability that the class is 1 plus 1 minus the actual class times the log of the probability that the class is 0. The negative sign exists because the logarithm is negative for arguments between 0 and 1. Log loss favors confident classifications that are correct. For instance, when the predicted probability of class 1 is high and correct, p-hat i is close to 1 for an observation, and yi is equal to 1. You can convince yourself by inspecting the formula that the log loss is small. Indeed, the first term vanishes because the log term tends to 0 as the probability approaches 1, while the second term vanishes because the factor 1 minus yi is 0. In this way, log loss penalizes confident, incorrect predictions. When the predicted probability of class 0 is high and incorrect, that is, when p-hat is close to 1 for an observation, and the actual class is 0, the log loss is very large. There are various ways to stop iterations, but essentially, you stop training when your model's log loss is satisfactory. Different techniques can be used to change the values of theta, and one of the most popular methods is gradient descent. Gradient descent is a clever iterative approach to finding the minimum of a function. It adjusts the parameter values in the direction of the steepest descent using the derivative of the log loss function. Gradient descent depends on a specified learning rate, which controls how far it's allowed to step the parameters on each iteration. The main objective of gradient descent is to change the parameter values and find a path to the optimal parameters to minimize the cost function. Consider the plot, which simulates a parabolic log loss cost function of the trial parameters theta1, theta2. This surface represents the error for different values of parameters. The gradient of the surface points in the direction of the steepest ascent. Thus, the negative of the gradient points in the direction of the steepest descent, hence the name gradient descent. The steeper the slope, the greater the magnitude of the gradient, and thus, the greater the step toward the minimum. You can control the size of each step by scaling the gradient by a factor called the learning rate. As the lowest point is reached, the slope diminishes to zero. This lowest point of the path occurs at the optimum theta1, theta2. Let's explore some additional features of gradient descent. The gradient of the cost function is calculated over the entire data set on each iteration. When the data set is large, gradient descent becomes very slow. You could try speeding up the convergence by increasing the learning rate, but convergence becomes less likely as the steps might be too big to notice the minima. Instead of using the whole, the cost function gradient can be approximated by choosing a random subset of the data to calculate it on. A variation of the gradient descent algorithm is stochastic gradient descent, or SGD. It's faster, but can be less accurate. It uses a random subset of training data and scales well. SGD is more likely to overlook local minima and find global minima of the cost function. It converges quickly toward a global minimum, but can wander around it for some time. The convergence can be improved by slowing down as the algorithm gets closer to a global minimum. You can home in on the minimum by decreasing the learning rate as you get closer, or you can gradually increase the size of the random data sample used to calculate the gradient of the cost function. In this video, you learned that the objective of logistical regression training is to predict classes with minimal error. The training process consists of key steps created to find a set of parameters, or theta, that minimize the cost function. An optimization step is used to find the best parameters. The metric for optimizing logistic regression is a cost function called log loss, which needs to be minimized. Log loss favors confident classifications that are correct and penalizes confident, incorrect predictions. Gradient descent is a clever, iterative approach to finding the minimum of a function. Stochastic gradient descent is a scalable variation of the gradient descent algorithm, which uses a random subset of training data.