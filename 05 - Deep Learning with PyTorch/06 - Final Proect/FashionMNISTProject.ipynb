{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2362746f-e6a7-4533-8835-fdc9b80292d0",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1ca0ae-82ff-469c-bdee-4636c2342349",
   "metadata": {},
   "source": [
    "<h1>Fashion-MNIST Project </h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00691e8b-48a8-49fe-8773-04eff69e84ee",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec26fda6-f5ce-4ed9-81c7-8cb4a67b23d5",
   "metadata": {},
   "source": [
    "<p>In this project, you will classify  Fashion-MNIST dataset using convolutional neural networks.</p>\n",
    "<ul>\n",
    "  \n",
    "<ul>\n",
    "<li><a href=\"#Preparation\">Preparation</a></li>\n",
    "<li><a href=\"#Q1\">Questions 1: Create a Dataset Class</a></li>\n",
    "<li><a href=\"#Q2\">Define Softmax, Criterion function, Optimizer and Train the Model</a></li>\n",
    "\n",
    "</ul>\n",
    " \n",
    "\n",
    "</ul>\n",
    "\n",
    "<p>Estimated Time Needed: <b>30 min</b></p>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a0ad03-954e-4845-bbde-fde818c43388",
   "metadata": {},
   "source": [
    "<a name=\"Preparation\"><h2 id=\"Preparation\" >Preparation</h2></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad252dc-5cef-46d9-9c48-12ce0c090cc9",
   "metadata": {},
   "source": [
    "Download the datasets you needed for this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f1b73-12f2-441f-80cb-a1a64732a6b7",
   "metadata": {},
   "source": [
    "The following are the PyTorch modules you are going to need\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d6f63b-30bf-400b-8ec4-a26b1e1a27fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (1.26.0)\n",
      "Requirement already satisfied: matplotlib in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Collecting torch==2.8.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.8.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Collecting torchvision==0.23.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio==2.8.0+cpu\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
      "Collecting filelock (from torch==2.8.0+cpu)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from torch==2.8.0+cpu) (4.15.0)\n",
      "Collecting sympy>=1.13.3 (from torch==2.8.0+cpu)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.8.0+cpu)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from torch==2.8.0+cpu) (3.1.6)\n",
      "Collecting fsspec (from torch==2.8.0+cpu)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from torchvision==0.23.0+cpu) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from torchvision==0.23.0+cpu) (12.0.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.8.0+cpu)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm-:--:--\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/abolfazl/anaconda3/envs/myenv/lib/python3.10/site-packages (from jinja2->torch==2.8.0+cpu) (3.0.2)\n",
      "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting networkx (from torch==2.8.0+cpu)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Downloading https://download.pytorch.org/whl/cpu/torch-2.8.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl (184.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchvision-0.23.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cpu/torchaudio-2.8.0%2Bcpu-cp310-cp310-manylinux_2_28_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, sympy, networkx, fsspec, filelock, torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [torchaudio]8\u001b[0m [torchaudio]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 fsspec-2025.9.0 mpmath-1.3.0 networkx-3.3 sympy-1.14.0 torch-2.8.0+cpu torchaudio-2.8.0+cpu torchvision-0.23.0+cpu\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "CPU times: user 4.74 s, sys: 1.33 s, total: 6.07 s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "%pip install pandas numpy matplotlib\n",
    "%pip install torch==2.8.0+cpu torchvision==0.23.0+cpu torchaudio==2.8.0+cpu \\\n",
    "    --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa3695-2ccb-46c1-8e64-424b147fd842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch\n",
    "# !pip install torchvision\n",
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb66e4-1c61-49f6-a504-733cec130184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Modules you need for this lab\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785159f3-f054-4c3a-805d-17a22f6c3784",
   "metadata": {},
   "source": [
    "Import Non-PyTorch Modules \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79861fb1-bc7e-461d-9862-aae70659e5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other non-PyTorch Modules\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2bc839-b789-4a2d-9543-d002492a180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(data_sample):\n",
    "    plt.imshow(data_sample[0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n",
    "    plt.title('y = '+ str(data_sample[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb8da66-32f2-4801-a756-d237bbe8a73c",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c022158-061d-4c8c-80c7-2b89587f81e1",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe4b23f-74e3-4c87-b850-df8392160dfb",
   "metadata": {},
   "source": [
    "<a name=\"Q1\"><h2 id=\"Q1\">Questions 1: Create a Dataset Class</h2></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a6a76-6b57-442b-87a3-2a6d1480aa7e",
   "metadata": {},
   "source": [
    "In this section, you will load a Dataset object, but first you must transform the dataset. Use the <code>Compose</code> function to perform the following transforms:. \n",
    "<ol>\n",
    "    <li>Use the transforms object to<code> Resize </code> to resize the image.</li>\n",
    "    <li>Use the transforms object to<code> ToTensor </code> to convert the image to a tensor.</li>\n",
    "</ol>\n",
    "\n",
    "You will then take a screen shot of your validation data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d2d9ff-9e06-438d-8dc8-5d3acd3e3399",
   "metadata": {},
   "source": [
    "Use the Compose function to compose the transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28356d8-a13a-436f-9e2a-948e8b9665b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint:\n",
    "\n",
    "IMAGE_SIZE = 16\n",
    "\n",
    "transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "transforms.ToTensor()#\n",
    "composed = transforms.Compose([transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95989521-fe35-4837-929e-3a6158b51a9a",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80697777-52b1-4055-b181-40783f073f1e",
   "metadata": {},
   "source": [
    "Create two dataset objects for the Fashion MNIST  dataset. One for training data called <code> dataset_train </code> and one for validation data <code>dataset_val</code>. You will be asked to take a screenshot of several samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173c1b5-1748-4bc5-aebb-40fcce0867f0",
   "metadata": {},
   "source": [
    "<b>Hint:</b>\n",
    "<code>dsets.FashionMNIST(root= '.fashion/data', train=???, transform=composed,  download=True)</code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81c758-0512-460b-af06-17833f51741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fashion-MNIST dataset objects (uses composed and IMAGE_SIZE defined earlier)\n",
    "dataset_train = dsets.FashionMNIST(root='.fashion/data', train=True, transform=composed, download=True)\n",
    "dataset_val = dsets.FashionMNIST(root='.fashion/data', train=False, transform=composed, download=True)\n",
    "\n",
    "print(f\"{len(dataset_train)} training samples, {len(dataset_val)} validation samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90877d2-0765-4fe9-a5e6-c0d2c1855057",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,data_sample in enumerate(dataset_val):\n",
    "\n",
    "    show_data(data_sample)\n",
    "    plt.show()\n",
    "    if n==2:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d86c3e-fc79-4573-814a-e3a2f130b9f0",
   "metadata": {},
   "source": [
    "<a name=\"Q2\"><h2 id=\"Q2\">Questions 2</h2></a>\n",
    "Create a Convolutional Neural Network class using ONE of the following constructors.  Train the network using the provided code then provide a screenshot of your training cost and accuracy with your validation data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eea87b-6a94-48ce-aa46-cfeda616e5f7",
   "metadata": {},
   "source": [
    "Constructor  using Batch Norm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b032680-e160-4739-b5c5-835b73d8c76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_batch(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, out_1=16, out_2=32,number_of_classes=10):\n",
    "        super(CNN_batch, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        self.conv1_bn = nn.BatchNorm2d(out_1)\n",
    "\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2_bn = nn.BatchNorm2d(out_2)\n",
    "\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, number_of_classes)\n",
    "        self.bn_fc1 = nn.BatchNorm1d(10)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x=self.conv1_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x=self.conv2_bn(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x=self.bn_fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fcb258-983b-4cb2-9bd7-3fee7e170b5b",
   "metadata": {},
   "source": [
    "Constructor  for regular Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e96a2-70ca-48bb-b9c6-1171bd436680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, out_1=16, out_2=32,number_of_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=out_1, kernel_size=5, padding=2)\n",
    "        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.cnn2 = nn.Conv2d(in_channels=out_1, out_channels=out_2, kernel_size=5, stride=1, padding=2)\n",
    "        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = nn.Linear(out_2 * 4 * 4, number_of_classes)\n",
    "    \n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        x = self.cnn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff6a521-a705-4473-bc9d-0a1c349cff8f",
   "metadata": {},
   "source": [
    "train loader  and validation loader \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb61b9c-844d-4dcc-935a-f65f273b77ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=dataset_train, batch_size=100 )\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset_val, batch_size=100 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd38757-ff72-47a8-b53c-761196f07430",
   "metadata": {},
   "source": [
    "Convolutional Neural Network object \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f34764-c741-45c2-94f4-8c93d38d2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CNN(out_1=16, out_2=32,number_of_classes=10)\n",
    "#model =CNN_batch(out_1=16, out_2=32,number_of_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b056110-1570-4963-85b5-765d9597b335",
   "metadata": {},
   "source": [
    "Create the objects for the criterion and the optimizer named <code>criterion</code> and <code>optimizer</code>. Make the optimizer use SGD with a learning rate of 0.1 and the optimizer use Cross Entropy Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15fb0e2-fdea-4d71-ae67-2727cf152a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model (choose CNN or CNN_batch)\n",
    "model = CNN(out_1=16, out_2=32, number_of_classes=10)\n",
    "# If you prefer the batch-norm variant, uncomment the following line and comment the previous:\n",
    "# model = CNN_batch(out_1=16, out_2=32, number_of_classes=10)\n",
    "\n",
    "# Criterion and optimizer for training\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f92188-b297-49d2-8b33-550435002d68",
   "metadata": {},
   "source": [
    "Code used to train the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cabeee-84ed-4794-aa38-27a9f0651445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "cost_list=[]\n",
    "accuracy_list=[]\n",
    "N_test=len(dataset_val)\n",
    "n_epochs=5\n",
    "for epoch in range(n_epochs):\n",
    "    cost=0\n",
    "    model.train()\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model(x)\n",
    "        loss = criterion(z, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        cost+=loss.item()\n",
    "    correct=0\n",
    "    #perform a prediction on the validation  data \n",
    "    model.eval()\n",
    "    for x_test, y_test in test_loader:\n",
    "        z = model(x_test)\n",
    "        _, yhat = torch.max(z.data, 1)\n",
    "        correct += (yhat == y_test).sum().item()\n",
    "    accuracy = correct / N_test\n",
    "    accuracy_list.append(accuracy)\n",
    "    cost_list.append(cost)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d2004-bf06-422c-93df-a10b53b270c9",
   "metadata": {},
   "source": [
    "You will use the following to plot the Cost and accuracy for each epoch for the training and testing data, respectively. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194c50c-2cf4-419d-9b6b-462d33c66685",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:red'\n",
    "ax1.plot(cost_list, color=color)\n",
    "ax1.set_xlabel('epoch', color=color)\n",
    "ax1.set_ylabel('Cost', color=color)\n",
    "ax1.tick_params(axis='y', color=color)\n",
    "    \n",
    "ax2 = ax1.twinx()  \n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('accuracy', color=color) \n",
    "ax2.set_xlabel('epoch', color=color)\n",
    "ax2.plot( accuracy_list, color=color)\n",
    "ax2.tick_params(axis='y', color=color)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fb29f3-a43d-4afa-91bc-678ec987ff41",
   "metadata": {},
   "source": [
    "dataset: https://github.com/zalandoresearch/fashion-mnist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e81c06-bfce-42c7-9aa9-8d132ecd9de4",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b482b-9ab0-4b24-a375-445d84b6ae93",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b8b1be-771c-4914-a01f-d7ebcd4db85d",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb388bb-d40d-4c61-9306-2e128f73ae43",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "prev_pub_hash": "f6dcb27f199dff848612e9e61ce1dbfeb0be13836cd1057108e853fd5463fa28"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
